[{"content":"At work, I\u0026rsquo;ve started working on a new code base. This has me thinking about the best way do this. Code can sometimes be a real pain. You aren\u0026rsquo;t just inheriting all the good stuff, you also take on all of the short cuts and half finished features that make up the technical debt of the project. A new code base is a package, you don\u0026rsquo;t get to choose only the good parts. So where to start?\nSometimes code can be intimidating, if not outright scary. Why is that? As the new owner of the code, you may be required to add features, fix bugs, or solve complex problems. Worse, you might be asked to do this in the middle of the night if you\u0026rsquo;re on call. So yes, something to consider. I really don\u0026rsquo;t like living this way, so I\u0026rsquo;ve been thinking of ways of relating with my work that are more positive. The feelings I enjoy most about my code is the sense of a job well done. There\u0026rsquo;s an aesthetic beauty to code, that you can only see once you\u0026rsquo;ve wrapped your head around it. Sometimes that feels like awe. Before my time, there were people who called themselves \u0026ldquo;craftsmen\u0026rdquo;. They took great care in the quality of their work. Some took it to the point of obsession. It\u0026rsquo;s not a cultural value that lives on today unfortunately. Perhaps we can revive it. At the end of the day, I want to love my work.\nSometimes I wonder what it is that I\u0026rsquo;m creating. You\u0026rsquo;d think it would be obvious. But software has a way of morphing into things beyond comprehension. In software, we build these enormously complex machines, constantly being worked on by many people. The direction shifts depending on the needs of the company and the users of the software. It\u0026rsquo;s not a surprise that things can turn into a mess. But how that complexity shapes itself is in part the expression of the developers working on it. Software that\u0026rsquo;s neglected or worked on carelessly, turns into a Rube-Goldberg. But careful attention and experience can create a beautiful work of art that\u0026rsquo;s a pleasure to maintain well into the future. I\u0026rsquo;m going for the art. But just for comparison, let\u0026rsquo;s look at a Rube-Goldberg machine here:\nNow let\u0026rsquo;s compare this with some of the work I saw a few years ago at the Miniature Engineering Craftsmanship Museum in Carlsbad. Here\u0026rsquo;s a picture of a custom made radial model airplane engine. I find this so beautiful.\nBoth are complex and achieve their purpose, but one has this sense of purpose and cohesion that stirs something in the soul.\nHere\u0026rsquo;s taste of this sense of craftsmanship from the Museum website:\nEvery part of Young\u0026rsquo;s planes were completed to his personal satisfaction. He built them solely by his own standards and expectations. Mr. Park didn’t build these masterful miniatures for entry in shows or contests. He noted that it was less important that the parts be technically perfect, so long as they \u0026ldquo;look and fit right.\u0026rdquo; With cutaway sections on some of these incredible miniatures, viewers can see that making these complicated parts come together is true artistry.\nWhile I might not have the luxury of completing my work projects to my personal level of satisfaction, that\u0026rsquo;s definitely something I can do with my own personal code.\nI started going through some of my old code that I still use. I have for example some code I use to download emails from Gmail to my desktop so they can be archived and searched locally. I have grand ambitions for all of that data, but for now it\u0026rsquo;s just a Python CLI that accesses Gmail and syncs with a local database. It was written over a weekend, and then one late night I got the great idea of adding a search engine to it. That didn\u0026rsquo;t end very well, and the code was left in a messy state. I had added a number of extra libraries to help with the search functionality, which made it really difficult to just do the simple operation of syncing my data. Just installing the dependencies was causing problems. It was definitely time for a refactor. So I used this as an exercise in taking a new look at old code. What would it take to give it a makeover?\nAs I went through the process, I made a list of the things I did to clean it up. And while the end product still had some major issues, the code itself was clean enough to inspire good feelings.\nI will discuss the steps I went through to get there. I think they are good model to follow if faced with code that fills you with dread.\nVisualize and Revise Dependencies Use a dependency visualization tool and take a look at what modules are importing.\nBe sure to take a snapshot of what your code looks like before you start, so you have something to compare your work against. It’s a very satisfying feeling to see your graph simplify and start to make sense. Here\u0026rsquo;s my before diagram:\nBefore Some things to look for:\nFrom the graph, do the imports make sense? Do all of the modules belong together, or should they be split up? Sometimes you have code that does very different things. They should not be grouped together, or share too many dependencies. You can see this sort of thing from the dependency chart. Does it look like a mess? What would clean it up? By just moving things around, you can really clean up the graph. For example, do all of those modules need to import from the database module? Investigate and find out why. By chasing down these messy leads, you can very quickly unravel your code. Remove anything that doesn’t belong in the module. It might be unfinished code, or code related to something else that is no longer needed. That code can be moved into a separate module, or just deleted. In my archiver code, there are a number of modules unrelated to Gmail. The Calendar and Photos modules are unfinished, so I have moved these into a separate project. Reorganize the modules such that the imports and dependencies for each module make sense. If you\u0026rsquo;re importing something that seems out of place, find out why. If the purpose of a module isn’t clear, this is a good time to make that clear. What does this module do? What belongs, and what doesn’t belong? You might have to create new modules to contain code that doesn’t fit. For this project I eliminated a number of modules, but I also created some new ones. Mostly this was just breaking up modules that were doing too many things, revealing their purpose more clearly. Are module names vague or meaningless? Names such as \u0026ldquo;util\u0026rdquo;, \u0026ldquo;data\u0026rdquo;, or \u0026ldquo;common\u0026rdquo; are terrible names that express what they do. Shared functions littered through the code can sometimes be suspect, so make sure their interfaces are stable, and consider moving them to another project if they really are generic enough to be shared. I have a \u0026ldquo;util\u0026rdquo; module with some code for dealing with primary keys and converting between formats. This could definitely be named better. Does this module diagram help me make sense of the code? What would help? At this stage, we don’t want to make any major changes. We are just moving things around, renaming things, removing unnecessary dependencies, and adding new ones to make things clearer from a high level perspective. The emphasis here is on high level comprehension. We will want to keep this perspective in mind as we perform other remediation steps.\nHere\u0026rsquo;s my after diagram, looking much more sane.\nAfter I did a little research an found some tools that work for the languages I use most. Here they are:\nGolang Tools https://github.com/lucasepe/modgv Python Tools https://github.com/thebjorn/pydeps Rust Tools https://github.com/regexident/cargo-modules https://git.sr.ht/~jplatte/cargo-depgraph Update the README One thing I noticed on my sus\u0026rsquo; projects was that the README was terrible. Either it didn\u0026rsquo;t exist, it didn\u0026rsquo;t contain any useful information, or worse, it was totally out of date and didn\u0026rsquo;t represent the project at all. The README might seem like something for \u0026ldquo;other people\u0026rdquo;, but I\u0026rsquo;ve found that it helps me a lot when I\u0026rsquo;m coming back to code I haven\u0026rsquo;t touched in a while. It\u0026rsquo;s a great reminder of what I was thinking. The README should be the last thing you touch after working with the code, and the first thing you touch when you pick it up again.\nSimple things are helpful:\nBackground knowledge that might be helpful, providing useful resources to get the user familiar with the problem space. Video walk-through. Instructional videos can also be very helpful for some developers, or managers who will never actually run your code, but they can watch the video and see it in action. A quick demo can really help someone understand what it does at a high level. You might already have done a walk-through of the code with other developers on your team. You can record it and post a link here. Required dependencies Installation procedures High level diagrams An explanation of the directory structure How to run the code How to test and develop the code. What is the workflow? What are some things you can do with the code? Are there examples? Examples are the best way to explain your code. What is the vision of the project? Non-goals? What is on the roadmap? How to deploy to production This doesn\u0026rsquo;t have to be a formal thing. Just helpful notes for the next person who comes along. Most likely that will be you. I see code all of the time on GitHub that looks very interesting, but I have no idea what state it\u0026rsquo;s in. Is this a work in progress? Is this ready for production? What is the plan here? If you\u0026rsquo;re going to make something public, the least you can do is put in a README that says, \u0026ldquo;Use at your own risk\u0026rdquo;.\nI always over-estimate my ability to remember things. As I\u0026rsquo;ve grown as a developer, one of the best skills I\u0026rsquo;ve acquired is knowing the kinds of things I will likely forget. That\u0026rsquo;s the sort of information that belongs here.\nTests must pass Run all tests and make sure they pass.\nThis should go without saying, but tests will often break a few months down the line as dependencies change. Some languages are worse than others for sure. It\u0026rsquo;s a good sanity check to ensure your code builds and tests pass. Bonus points if you have a CI job that builds your job weekly. GitHub can do this for free. Not every code base needs this. But if it\u0026rsquo;s something you use or depend on, consider automating those tests.\nBroken tests also point to problems in your code. This is a good time to eliminate useless tests, or to clean things up that aren\u0026rsquo;t clear. Coming into a new code base with a fresh set of eyes can really help you zero in on the issues. Even if you don\u0026rsquo;t have time to address them, make notes in the README, or leave a TODO in the code.\nUse a linter Turn on linters and track cyclomatic complexity.\nI find linters really helps clean things up. I can\u0026rsquo;t believe the problems linters find. Often bugs are uncovered, and it draws my attention to the parts that can really use some help. Take advantage of this automated tool. Of course, not all lints are helpful. But no linter is definitely not helpful. So turn the linter on and let it help you.\nYou can disable unhelpful lints using the configuration file.\nIf you find some code that really needs attention, and you don\u0026rsquo;t have time to get to it, make notes in the code about what you\u0026rsquo;re thinking. It will save you time later. Don\u0026rsquo;t just disable the lint because you don\u0026rsquo;t have time. It\u0026rsquo;s better to leave the lint on, so it will bring you back to that part of the code again in the future.\nOnce your code is lint free, add a lint step to your CI, or a pre-commit hook that will fail if lints are present. It\u0026rsquo;s a nice bar to set, and will keep things clean going forward, especially if there are other developers on the project.\nCyclomatic complexity can draw your attention to areas that might be needlessly complex. Cyclomatic complexity however is not a good objective measurement, so you should take it with a grain of salt. You can use it to find a baseline that you’re comfortable with on your project, and then use your linter to set up a maximum.\nHere are some tools I found helpful:\nGolang https://github.com/fzipp/gocyclo Python https://pypi.org/project/mccabe/ Rust https://github.com/rust-lang/rust-clippy Refactor notoriously difficult to read code As I\u0026rsquo;ve gone through the code so far, I usually start to notice things. Classes that don\u0026rsquo;t make sense, or don\u0026rsquo;t have a clear purpose. Code that hard to comprehend. Code that\u0026rsquo;s most likely broken. Now is a good time to dig in and take a look. When I was doing my cleanup, I was specifically looking to refactor code that would help me clarify things at a high level. I wasn\u0026rsquo;t changing how things work, just trying to get cleaner interfaces. On the archiver, I created some classes that helped simplify a lot of the functions I was using.\nBe on the look out for:\nDeeply nested for loops, or nested logic statements Double negatives. Try to ensure all functions that return booleans, do so in the affirmative. It’s not always clear what the affirmative actually means, but it can help clarify the intention of the code. Complicated boolean logic. Long strings of boolean operators are almost impossible to figure out at a glance. Lots of bugs hide in there. For complicated logic, I often accompany the difficult code with a truth table in the comments to make absolutely sure I have covered all of the cases properly. I have found a lot of bugs this way. Anything else that makes you stop and say \u0026ldquo;What?\u0026rdquo;. Eliminate errors and noise from your logs One thing I find very annoying when I inherit new code, is seeing lots of errors in the production logs. If I\u0026rsquo;m on call and I redeploy the code, how do I know if something is working or not? How can I find a new error, when there are so many already? This sort of low signal to noise ratio is a great pain, and is a sign of neglect.\nHere are some opinionated tips for logging:\nIt’s fine to have verbose logging, but make sure that those messages are flagged as debug. Info messages should actually be informative and low frequency. Error messages should be unexpected and actionable. Things like timeouts on a high volume system are just part of doing business. You don\u0026rsquo;t want to ignore these of course. A lot of errors can be turned into metrics, counted and visualized in a dashboard. From there you can determine a normal rate and create an alert if things get out of line. It\u0026rsquo;s much easier to notice a problem with a frequency spike on a dashboard than in the logs. Errors should indicate that there is a major problem and to consider reverting the deploy. Taking these actions will greatly reduce the noise in your logs. There’s nothing more annoying that deploying your code and seeing a bunch of errors that have nothing to do with your code. It really adds to the stress of the job. If an error shows up, that should mean what it says, \u0026ldquo;ERROR\u0026rdquo; and your your code is not ready to be deployed. Fix the error first if you can. Alternatively you can track your errors in Sentry, and start tackling them one by one as you find time.\nErrors are important, but if they get lost in the logs, they lose their value. Chasing down this noise will bring you to code that can really use some more attention, and you will likely find bugs. Sometimes it’s just errors that need to be handled explicitly and tracked as metrics.\nConclusion I will probably add to this list in the future, but this was all I did. It took me an hour or so for each code base I touched, and it was a surprisingly good use of my time considering the results. I can honestly say I feel better about my creations after taking this \u0026ldquo;craftsman\u0026rdquo; look at my work.\n","date":"2023-03-15","permalink":"https://rrx.github.io/posts/2023-03-15-new-code-base/","tags":null,"title":"New code base, where to start?"},{"content":"TL;DR Here\u0026rsquo;s a sketch of a solution for hot-reloading that I hope will bring some greater flow to my development process. Present day solutions are more about shipping the final product, than they are about enjoying the process of coding. Hot-reloading is one of those features that once you have it, you just don\u0026rsquo;t want to live without it again. So let\u0026rsquo;s get hot-reloading like it\u0026rsquo;s 1972!\nSome hot-reloading please Smalltalk was revolutionary when it came out. It was totally unlike anything that had come before. It wasn\u0026rsquo;t perfect, but what it was changed how people thought about personal computing, influencing much that came later. Some have speculated on why Smalltalk wasn\u0026rsquo;t more broadly adopted, but we will never really know. What I do know is that Smalltalk was very cool in 1972, and we don\u0026rsquo;t have anything close to that today. We certainly have some cool technology. But what we lack is the experience Smalltalk provided to the developer. This was during a time when punch cards were still in active use. I think we have lost some of what Smalltalk was supposed to be, and I\u0026rsquo;m interested in what it would take to have something similar today.\nThe specific feature I\u0026rsquo;m interested in is the ability for Smalltalk to modify it own code while running. This sounds outrageous to us today. Almost foreign. Something you might only see in a toy, not a production ready computing system. But if you think about it, we actually do this all the time when working on large distributed systems. We are constantly modifying the code of the actors within the system while the entire system continues to run. There\u0026rsquo;s zero downtime in modern internet based systems. And there\u0026rsquo;s an army of developers behind the scenes working to make sure that continues to be the case. Continuous Delivery normalized this, and it\u0026rsquo;s the standard today for SaaS applications.\nWhat a developer mostly does is edit some files, with the help of some clever IDE tools. The compiler then builds and links the code into a final executable. At which time tests are run, or the application is started for manual testing. In my early C++ days, it wasn\u0026rsquo;t uncommon to wait several minutes for the application to build before I could verify my changes. It was tedious work, and it lacked a sense of flow that I longed for. As a kid, I programmed on a Commodore Vic 20, using a primitive Basic that only supported line editing. But with only that, I was able to create some interesting programs for a kid. There was no development cycle. The changes I made were almost instantaneous. That\u0026rsquo;s one of the advantages of interpreted languages is that sense of instant feedback. Those atrocious C++ build times are a big reason why dynamic languages really took off in the 90s. The trade-off with the fast start up times of those dynamic languages was very compelling, and sparked a lot of exploration.\nOne of the possible reasons why Smalltalk didn\u0026rsquo;t take off was likely because dynamic languages were able to do much of what Smalltalk did, without many of it\u0026rsquo;s limitations. The ability to quickly prototype an idea and see it in action is something developers wanted. Tcl (1988), Python (1991), Ruby (1995) came out providing instant start up times and live interaction through the REPL. This sort of thing has been around since the early days of Lisp, but computers with better graphical displays kicked off the computer hobbyist revolution, Lisp didn\u0026rsquo;t quite make it into the mainstream. It was something you did at University. (Some notable exceptions of course).\nSo that\u0026rsquo;s my superficial take on the last 50 years of programming languages. What I really want to know is what is it going to take to bring that sense of programming flow back to my work. The feeling like I\u0026rsquo;m affecting things immediately. The ability to quickly explore new ideas and try new things. But mostly, the ability to not have to wait to see the results of my changes.\nDynamic and scripted languages are definitely an option. I have worked in python for 20 years and I love it, but I never want to build anything big in it every again. Optional types in Python 3 make things tolerable. But compared with a proper type system like in Rust, the short term gains you get at the beginning of a project are lost later on as complexity rises. You hit your complexity threshold sooner with untyped languages.\nThe gamedev world has come up with a lot of clever solutions to get hot reloading to work in C++. So I know there are other developers who are interested in this sort of working with near instant feedback loops. In gamedev back in the day, it wasn\u0026rsquo;t uncommon to be waiting hours for your program to build. Being able to hot-reload can be a huge time saver. Most of these techniques are limited, and come with restrictions like not being able to modify the function signature, or modify structs in any way. But for game dev, that\u0026rsquo;s often fine, and plus, what choice do we have? The options in C and C++ are limited. Handmade Hero is an example of a game that was developed on a live stream, and it featured hot-reloading that the author built himself.\nThere are lots of reasons why hot-patching code might be helpful, but what gets me interested is the chance to improve my development flow while using statically typed languages, such as Rust or C++. I can get this already with Python, but that\u0026rsquo;s not what I want to use all the time.\nOther interesting uses might include dealing with large state files that take a long time to load. This was one of the big reasons for one of the Jupyter notebooks. In Jupyter, you can load your data files into the kernel, and then do exploratory work from there. It\u0026rsquo;s a great way for data scientists to explore their data. The final reason this is interesting to me is because it\u0026rsquo;s something that should be possible, but isn\u0026rsquo;t. Pharo, a modern open source implementation of Smalltalk, can edit it\u0026rsquo;s entire system, even the JIT based VM it runs on. That\u0026rsquo;s impressive. I\u0026rsquo;m not interested in programming in Smalltalk through, so unfortunately I\u0026rsquo;m out of luck. So let\u0026rsquo;s see what it will take to make these goodies possible.\nHere\u0026rsquo;s a screenshot of a Juptyer session exploring COVID data. The data set was large, but I was able to query the data in ways that were helpful to me in the early days of the pandemic to understand the scale of the problem.\nIn C++, there\u0026rsquo;s usually some sort of variation on the dlopen approach, which is quite simple. It involves watching for changes in shared libraries, and then getting the updated functions from the modified library so they can be called.\nHere\u0026rsquo;s some pseudo-code to describe the a simplified version of the dlopen approach:\nloop: lib = dlopen(\u0026#34;hotreload.so\u0026#34;) f = dlsym(lib, \u0026#34;func\u0026#34;) loop: f(0) # call the new function if changed(\u0026#34;hotreload.so\u0026#34;): break This method is easy to use in simple cases where the functions have simple parameters. You don\u0026rsquo;t have to consider changes in the function signatures. If you did change the function signature, it would have undefined behavior. While incredibly powerful, I\u0026rsquo;m hoping to go much further.\nMy Wish list So I\u0026rsquo;ve come up with my wish list for features I\u0026rsquo;m looking for in a language or system that supports hot-reloading. Something like Smalltalk, Emacs, or live-reloadable SPAs, but closer to native, and to the tools I want to use. I know a lot of these features are available here and there in different languages and products. Rather than reinventing the wheel, I want to come up with something that doesn\u0026rsquo;t exist yet. I program a lot in Rust these days, and my C++ has gotten a bit rusty you could say. So I\u0026rsquo;m hoping for a solution close to that world. Hot-reloading in Rust is possible using the dlopen approach, but I think we can do better than that.\nProvide hot-reloading that\u0026rsquo;s both fast and safe. And by safe, I mean memory safety issues, such crashes due to accessing data after it\u0026rsquo;s been freed. And by fast, I mean something close to C++ in performance. Safe interop with C based libraries. No VMs if possible. VM\u0026rsquo;s can provide some great solutions, but they abstract you from the hardware, and tie you into specific ecosystems. I\u0026rsquo;m hoping to stay as close to the metal as possible, so that things like hot-reloading device drivers could be a possibility. (Bad idea? Maybe). Have the ability to modify my statically compiled editor or IDE while it\u0026rsquo;s running. Modifying an interpreted one is too easy, and also too slow. Emacs allows this, and is a big inspiration, but at the end of the day, I don\u0026rsquo;t enjoy that world. Hot-reloading is a zero cost abstraction. This means that if I disable hot-reloading, there should be no performance penalty. For example, if I disable the feature in the release build, it should have performance close to C++. Ability to hot-reload on embedded devices safely by uploading compiled code fragments over serial. Provides near instantaneous feedback on changes to code. Possibly bypassing the filesystem altogether, compiling code in the buffer and swapping to it without even hitting save. Provide a rich debugging experience which allows you to debug your application while it\u0026rsquo;s running. This is is pretty common. But combined with safely hot-patching of code, and stack restarts, this can be a very powerful thing. Deep integration with the editor and IDE, by providing a stable hot-patching API that can be used to build an application on a running application. This API could be used to build a REPL as well for live coding in a session. Provides a \u0026ldquo;Playground\u0026rdquo; like Swift. These are incredible tools for productivity, and every developer should have access to them. Be able to access data in memory in such a way that it can be graphically visualized in real-time, allowing the ability to visualize large, or fast moving datasets. Be able to modify any part of the running code, which could include things like the compiler or device drivers. This could break everything, but as long as you can disable that ability in the final product, it\u0026rsquo;s a tool to speed up development and foster an environment of exploration and innovation. This includes the ability to modify structures and function signatures, something that is almost impossible using other methods. It\u0026rsquo;s possible though, as proven by the Mun language Must have bounded memory. It\u0026rsquo;s not much use if you run out of memory eventually because you never release code that\u0026rsquo;s been run. The trick here is to make sure it will never be run again before releasing it. At the end of the day, I want to be able build a cathedral of code without ever having to restart the program. It sounds impossible, in an age where the solution to most computer problems is to restart your computer. But this post is all about a dream. And there\u0026rsquo;s no technical reason why it can\u0026rsquo;t be done. While this might not be possible in Rust or C++ yet, here\u0026rsquo;s how I think it might work.\nMethods There are three methods that can be used to accomplish live hot-patching of code that I\u0026rsquo;ve been able to identify.\nCode Rewriting Function Hooks Functions with non-static lifetime Code Rewriting Code Rewriting at a high level means wrapping code in a lock, and then rewriting the code in place. This really only works if the code you are rewriting in place is the same size or smaller than the existing code. You can get around this by only writing a jump instruction to the location of your code. There are some commercial and research solutions that do just this in order to do dynamic binary instrumentation. Some examples are Pin and Dyninst.\nAccording to the authors of this paper, \u0026ldquo;Locked operations are not atomic with respect to instruction fetch when they operate on multiple cache-lines.\u0026rdquo; What this means effectively is that locks are not sufficient to provide safety when modifying live code. The authors go on to describe an extraordinary method which does work. It gives you a sense of what might be required to actually be able to rewrite code in place. In addition to this, locks are required, which for the use case I\u0026rsquo;m exploring introduces the possibility of deadlocks which might be hard to reason about.\nIt might be possible to use this method, but the complexity and potential draw backs got me thinking about simpler alternatives.\nFunction Hooks Function hooks take advantage of some compiler tricks to be able to atomically and safely hook code. It does this by adding a 8-byte NOP instruction at the beginning of every function. There are compiler flags that can enable this, and it\u0026rsquo;s common in Windows code. Because the NOP is a single instruction, there\u0026rsquo;s no problem with dealing with instruction pipeline.\nSee: Why do Windows functions all begin with a pointless MOV EDI, EDI instruction? Chris Wellons wrote up [an excellent description of the method and how it works.] (https://nullprogram.com/blog/2016/03/31/) Definitely work a read. The takeaway from this is that if you have a little help from the compiler, it\u0026rsquo;s possible safely hook your code, and provide new implementations. This looks very much like the approach taken by Swift to implement dynamic replacement.\nOne advantage of this approach is that you are able to provide a stable function interface that you can export, or that might be depended on by external code. The function pointer will never change, that can be helpful if you are unable to track references in your application. Function hooks work when the function lifetime is static, meaning it\u0026rsquo;s statically allocated by the loader before any code actually runs, and you can never release it, making it impossible to have a use-after-free error. This is very safe, which is what we are looking for. And it\u0026rsquo;s relatively simple.\nYou can even modify the function signature. The new function you hook in can expect a different set of parameters. The problem however that arises here is that unless you can account for every caller of your function, and ensure that they will use the new signature, and coordinate that with the moment you hook the function, then you can\u0026rsquo;t guarantee that it won\u0026rsquo;t break your system. For this to be safe we need a way to ensure all callers match the function signature, which can never change. It\u0026rsquo;s a limitation that\u0026rsquo;s worth the stability. You can work around this by doing things like soft restarts, which reset execution, but that\u0026rsquo;s no really what we want here.\nHooks can work great if you need to pass a stable pointer to a function with undefined lifetime. This means passing a pointer to a function that could use it anytime between the call and the end of the program. That pointer is guaranteed to exist because it\u0026rsquo;s static. This method allows us to have a static method that can also be hot-patched.\nAnother win for hooks is that you can dynamically patch code that knows nothing about your hot-reload mechanism. The only thing you need is a compiler that can apply the appropriate hook at the beginning of the function. This will be very important for C interop, a feature I would very much like to enjoy.\nSo what about this function that we use to patch our function. Is that static as well? If so, we could quickly run out of memory because you can\u0026rsquo;t free static functions safely. To do so, we would have to ensure that nothing in the program can ever call that code again. And this is actually impossible to guarantee without a complete lifetime accounting of all objects in the system. There are all sorts of examples of different types of code that can break things unless you assume safety. So to achieve this, we need to consider another method to complement these hooks, and that\u0026rsquo;s functions with non-static lifetimes.\nFunctions with non-static lifetime When we hook a function, how do we guarantee that the code will never be run again, allowing us to free code that\u0026rsquo;s no longer in use. One possible solution is to use reference counting. Each function needs to increment a reference count on function entry, and decrement that function on exit. Also, any function which holds a pointer to the function also needs to increment the reference count. When no one holds a pointer, and the reference count is 0, we can then safely free that memory. This is a lot to keep track of, and seems complex, but it turns out that Rust is very good at doing this exact thing. Rust guarantees that object lifetimes are respected using a combination of compile time and run-time guarantees. The compile-time guarantee is what\u0026rsquo;s known as the \u0026ldquo;borrow checker\u0026rdquo;. Among other guarantees, it ensures you will never use something that\u0026rsquo;s already been freed. The run-time guarantees are provided using reference counting. This does place some limits on the kinds of programs you can write, but the trade-off is safety, exactly what we are looking for.\nThere are some gotchas though. For example code that never exits. If a function never exits, it can never be released. This can happen if it\u0026rsquo;s a forever loop, or if the code executes a longjmp. Some care needs to be taken in these situations. Longjmp might not happen very often, but loops are everywhere.\nProposal So my proposal is this. Functions with non-static lifetime, guaranteed with a combination of compile-time and run-time checks, gives us just what we need to build a cathedral of code in a single line of computation. But to be certain, what we want is a cathedral, and not a house of cards. So the next step is to make sure I haven\u0026rsquo;t missed something important, and get a better understanding of how this might work in practice.\nEven though Rust is really good at tracking lifetimes, when you write a Rust function, there\u0026rsquo;s an implicit assumption that the function has a static lifetime, which makes sense. In order to do the sort of coding I\u0026rsquo;m proposing, you would need to write the entire program using function pointers. Rust supports this, but I\u0026rsquo;m not sure what that would look like. We can allow main to be static, but beyond that could we build something where every function (other than main), is hot patchable. I\u0026rsquo;m pretty sure the answer is either no, or that the monstrosity you wrote would be completely unmaintainable. Rust doesn\u0026rsquo;t actually do what we need to do here, which tells me this might be one of those rare problems where a new programming language is required.\nA programming language that:\nGuarantees memory safety at compile-time and run-time First-class support for functions with non-static lifetimes. What this would look like in practice is being able to write a function once, and run it. And re-write the function as many times after as you like, and the language keeps track of each version as an object in memory, rather than in a static compile time layout. Those dynamically created functions are freed only when safe, giving us the bounded memory we want. And I believe this meets all the requirements I\u0026rsquo;ve set out in the post. Let\u0026rsquo;s review those requirements.\nConsiderations The requirements that deserve further consideration are:\nsafe C interop hot-reloading as a zero-cost abstraction fast like C++ ability to hot-reload on embedded devices ability to modify any part of the code while running, including structs and function signatures global state Safe C Interop How can we not only get full C-interop, but also full hot-reloading of any C function? C doesn\u0026rsquo;t provide this kind of support for sure, so there\u0026rsquo;s no help there. But if we are able to provide a lifetime aware function signature for a C function, that will allow us to treat C functions as hot-reloadable. If we get the signature wrong, then things go badly. This is exactly what Rust needs to deal with in order to work with C. So what I\u0026rsquo;m proposing here isn\u0026rsquo;t very new.\nIt\u0026rsquo;s easy to imagine a C function that can abuse the system. These sorts of pathological functions should just not be used. That\u0026rsquo;s a limitation for sure, but most useful, and well written C APIs have very clear lifetime signatures, even if they aren\u0026rsquo;t explicit.\nWe can even change structs if we want to. Changing a struct however changes the signature of any function that uses it, making it incompatible with any existing state using the old structure. This is a good and keeps things safe. Mun solves this problem by providing clear casting rules for struct changes. There are options here that can be explored further.\nAs long as we have appropriate lifetimes on the C function signatures, and our system ensures safety, we can hot-reload C functions and even modify structs and function signatures. I can foresee a situation where you make a change to a function, which makes it incompatible with what\u0026rsquo;s running at the moment. In this case it might appear as if your function isn\u0026rsquo;t being hot-reloaded. This would likely be confusing to a user that\u0026rsquo;s expecting it to run. But the callers are not yet aware of the signature change. This sort of a problem would usually be caught as a type error during static compilation, and this situation would be no different. The entire program doesn\u0026rsquo;t compile. That\u0026rsquo;s a good thing. Once the type issues are fixed, the code can load. If code paths have diverged, there may need to be a mechanism to reset program flow further up the stack, a straight forward operation typically done by debuggers. More importantly, for a good user experience, there may need to be some indication to the user at which stack level the code diverged, so the user can properly reset execution. These sorts of debugger operations become essential in this dynamic environment.\nZero-cost abstraction Zero-cost abstraction means that if don\u0026rsquo;t want to use this hot-reloading stuff, the language does not suffer the performance cost. There\u0026rsquo;s likely going to be some performance hit to support this. It should be easy to compile a version of the code the interprets the functions as having static lifetimes. This will likely open up a lot of optimizations that were impossible in the non-static scenario. I definitely want that, especially for the case where you want to ship your code, and you don\u0026rsquo;t want your users, or hackers messing with things. Solving the non-static problem is the hard part, if we can solve that, static functions should be easy.\nFast like C++ Once the functions are downgraded to static lifetimes and everything is compiled, there\u0026rsquo;s no reason why it wouldn\u0026rsquo;t be as fast as C++. All of the code related to hot-reloading is removed, and all your left with is your code. I think of this like a Python wrapper that runs C code. If you compiled out the Python part, all you would be left with is C.\nEmbedded device support Embedded devices present an interesting opportunity. I\u0026rsquo;ve worked as a firmware developer, and I can definitely say it\u0026rsquo;s even worse than doing C++ application development. No only are you using some out of date fork of gcc to compile your code, but you also need to flash the hardware, which can take almost as long as the compilation step. There\u0026rsquo;s definitely an opportunity here to really speed things up. These devices are memory constrained, so memory can be tight. I can imagine this working by having a smart bootloader that implements the memory safety guarantees, which listens for compiled code updates from the host. And patches it\u0026rsquo;s memory space. It wouldn\u0026rsquo;t require a full toolchain, that work can be done on the host. It just needs a smart boot loader. Some of that intelligence might be able to live on the host even, in which case the boot loader just accepts commands to write code into memory, and some other debug commands, and you have yourself a hot-reloadable embedded device. No more flash rewrites. Developers will be very very happy.\nModify any part Will this give us the ability to modify any part of the code? I think it does. It even allows us to rewrite main. In order to actually run the new version of main though, you will need to pop the stack right back to the beginning. To do this safely, we would need to unwind the stack cleanly, similar to how exceptions work. We can\u0026rsquo;t just reset the stack pointer to the start unfortunately, there\u0026rsquo;s likely a lot of state in the stack tracking things like lifetimes and reference counting that need to be run in order to clean things up properly. So exceptions would be necessary in the language in order to support this. Rust interestingly doesn\u0026rsquo;t support exceptions. Exceptions doesn\u0026rsquo;t have to be something that\u0026rsquo;s supported if hot-reloading is disabled, it just needs to be supported to do this sort of stack restarting, which is effectively an exception that gets thrown and then caught up the stack somewhere. The functions may require special compilation in order to support this.\nBut with that support in place, we should be able to modify everything, even main!\nGlobal State What about global state? One of the big problems with complex software is you have all of this state all over the place, and the complexity is such that the total number of states your program can be in is more than the total number of atoms in the universe. It doesn\u0026rsquo;t take a very large program to get there. Clearly it\u0026rsquo;s impossible to handle every possible state a program can be in, so we take care to keep that state to a minimum and try to prevent illegal states before they ever happen. Programming in this new way opens up new opportunities for crazy states, and I think extra care is warranted to manage it properly. The compiler should block programs from being loaded that do clearly illegal things, but that doesn\u0026rsquo;t cover all of the legal things a programmer can do.\nUsually with a program, it runs only once. But if you\u0026rsquo;re hot-reloading, you can make a change, and put state into something strange, and then correct your mistake. Even though you\u0026rsquo;ve fixed the function, the state may still be broken. This may lead to all sorts of hard to detect bugs, because the code that created the state is no longer visible to the programmer. Good debugging tools can go a long way. But most importantly, the user needs to be able to reset their state to something expected. We can try to use data structures to make impossible states unrepresentable, but that\u0026rsquo;s unlikely to always be the case. One of the challenges of this sort of programming, is learning how to build and construct software that makes resetting state easy. It\u0026rsquo;s not something we normally think about. But if you\u0026rsquo;re building a cathedral from the inside out, it makes sense that there is some methods of construction that work better than others. That would be the art of this sort of programming. The complexity could easily get out of hand very quickly. And that might be a good thing, because it forces the developer to constantly think about state and it\u0026rsquo;s lifetimes.\nVery likely, a good garbage collector will be a lifesaver here. Though I don\u0026rsquo;t think it\u0026rsquo;s essential.\nNext Steps So what\u0026rsquo;s next? Now that I have a pretty good idea of the problem, I\u0026rsquo;m going to look into a small proof of concept. I have already created a rudimentary in-memory linker in Rust with support for creating and freeing functions. It uses persistent data structures to keep track of the functions, and because it\u0026rsquo;s written in Rust, I\u0026rsquo;m pretty confident that it\u0026rsquo;s safe. Most of the challenges I had were in understanding how linkers work, so I could do the same thing, just at run-time and in memory.\nTo better understand things, I ended up writing a very simple x86-64 ELF linker in Rust which can link C object files and dynamic libraries. It\u0026rsquo;s passing the tests at the moment, and it was quite an achievement. It took over my evenings for a few months. So with this understanding, I think I\u0026rsquo;m ready to create another proof-of-concept.\nI\u0026rsquo;d like to include the following:\nEnsure executable memory is properly protected, being marked as RX only. We can do this by mapping the same memory twice into the process. Once as RW, and the second time as RX. This will provide further safety guarantees to ensure that running code doesn\u0026rsquo;t accidentally overwrite itself. Get linking working properly in memory. One thing I learned with my POC is that if you want to do hot-linking, it\u0026rsquo;s actually a lot easier than building a static linker. You don\u0026rsquo;t need to worry as much about the ABI. You still need to worry about it, but you can simplify a few things. My first attempt I made some mistakes, which should hopefully be corrected based on my experience with the static linker. Work on improving the C-interop, so that C functions can be properly specified to be lifetime aware. This will allow me to treat C functions as reloadable. To do this, the runtime will need to keep track of the function signatures. If this signature is incorrect, it will likely crash everything, but as long as the function signature matches the implementation (which C does not guarantee), everything should work. I mostly want C for interop, not as a language to program in. It\u0026rsquo;s not the best fit. But it\u0026rsquo;s simple and easy to understand for a proof of concept, and it will allow me to test my theory without having to invent a new language. That\u0026rsquo;s what I\u0026rsquo;ve got so far. I can\u0026rsquo;t wait to be hot-reloading like it\u0026rsquo;s 1972!\nSimilar Projects Mun Nim C++ options Hot-reloading in Rust Hot-reloading in Python using Reloadium Swift Swizzling References Living on the edge: Rapid-toggling probes with cross modification on x86: A great paper that describes the difficulties that self-modifying code presents for modern CPU architectures. ","date":"2023-02-13","permalink":"https://rrx.github.io/posts/2023-02-13-hotreloading/","tags":null,"title":"Hot-Reloading like it's 1972"},{"content":"I just finished reading \u0026ldquo;Managing Technical Debt\u0026rdquo;, and while it provides some excellent ideas on the topic, I felt like it was missing something vital. The book focuses primarily on the technical side of the problem. The human factors however, are just as important. Not including them in our assessments is a major reason why we have so much trouble assessing the true cost of our technical debt. I think this omission is common in the industry, and I think it\u0026rsquo;s time to change that.\nBut before getting into what I think is missing, it\u0026rsquo;s worth mentioning that the book does provide some excellent strategies. Many of them are common sense. I most appreciated the section which provides a decision making formula for calculating the cost of the debt to determine if the benefits are worth it. This sort of decision making is very rare in the industry however, because we often have a poor idea of the true cost. In many cases, we hardly even know what we are building before we build it. For a start-up that\u0026rsquo;s striving to find their product-market fit before running out of their Angel money, this is the difference between success and failure. But overall it was a great overview of the technical sources of debt and how to address them. The earlier the better.\nHowever, technical debt is not purely a technical problem, it\u0026rsquo;s also a systems problem. The idea of a systems problem might be new to people, so I will describe what I mean. Systems are complex systems that involve multiple agents and factors and an associated web of interdependencies. With modern software systems, and the large organizations that build them, it\u0026rsquo;s easy to get lost in that web. Systems level thinking is very different from linear thinking. Linear thinking is common in the scientific world, because it reduces the problem down to a single cause and effect, which can be easily tested. The goal is to eliminate other factors to reduce the experiment down to test only one thing. This is incredibly helpful, but it falls short when trying to understand a complex system, for example, a natural ecosystem.\nMost of what we know about systems comes from the scientific study of ecological systems. Plants, animals, bacteria, and humans form complex interrelationships which are hard to understand in isolation. A common example comes from Yellowstone park. Years ago the wolves in the area were hunted to extinction. But surprisingly, this had significant effects on the waterways in the area, causing serious problems. The recent reintroduction of wolves to the ecosystem brought back balance to the system in a dramatic comeback.\nHere is a diagram of the positive interactions between elements in the ecosystem at Yellowstone. See Baker 2016. We will compare this later with an interaction diagram from a software company.\nSoftware systems are like ecosystems. This might be hard to see, because we try very hard to keep those interactions as simple as possible. Arguably, a well designed system has fewest interdependencies possible. We like to think that our UI depends on the API. The API depends on the Database, and the Database depends on some 3rd party. Sounds simple, but there\u0026rsquo;s much more to it. Consider the following scenarios There\u0026rsquo;s a cloud provider on which you run your software, which just deprecated the version of PostgreSQL that your API depends on. There\u0026rsquo;s a build and deploy system that tries to remove the human element from deployment, but ends up creating its own maintenance burden when a bump in the Kubernetes version breaks everything bringing development to a standstill. The CTO has declared the API deprecated and to halt all feature development, but the alternative was supposed to be ready last month and everyone is still waiting, forcing developers to find awkward workarounds.\nIn a complex system, if you change something, it often has unexpected consequences. The consequences are unexpected, because we often have a poor model of how things actually work. In my experience, the few people in the company who do actually understand it all, are poorly paid and over worked. The problems the organization faces find them, but because they aren\u0026rsquo;t problems that are recognized by management, they aren\u0026rsquo;t given the recognition they deserve.\nThe \u0026ldquo;Debt\u0026rdquo; metaphor is easy for people to initially grasp, but it\u0026rsquo;s insufficient to describe the effects I\u0026rsquo;m talking about here. In many cases, the metaphor of debt can be misleading. Debt is a linear phenomenon, with a clear relationship between principle and interest. Interest grows exponentially, and we sort of understand that. But it\u0026rsquo;s a single relationship. To stretch the metaphor into a system, you have multiple principals and multiple interest rates and are each compounding each other in ways the accountants don\u0026rsquo;t quite understand. And worse, they don\u0026rsquo;t even know what the balance is at the end of the day. This more accurately represents the predicament the software industry finds itself in. Left unchecked, we leave ourselves very vulnerable to small changes in the environment, such as market pressures. How can we really say we are being responsible for this problem if we only consider its \u0026ldquo;easy\u0026rdquo; to quantify parts. This measurement bias is very much as the source of our trouble. Without an understanding of the full problem, our solutions are ineffective, or at worst, counter productive.\nA clear idea of the problem of technical debt is vital before we can begin to entertain solutions. \u0026ldquo;Managing Technical Debt\u0026rdquo; offered numerous solutions to the technical challenges presented. But as a practitioner in the field, those solutions felt weak and overly simplistic. They fail to grasp the situation that many companies find themselves in. This was my motivation in writing this article, to gain a clearer picture of the full problem. From there we work towards an enduring solution. As the saying goes, \u0026ldquo;A problem well stated is a problem half solved.\u0026rdquo;\nAs part of my exploration, I tried to capture the elements of the web of interconnections in a software system as I have experience them. I was expecting to find some sort of feedback loop, where one effect feeds another and so on. But what I found was that there are multiple feedback loops, each feeding into the other, and not in a good way. Here\u0026rsquo;s what I\u0026rsquo;m talking about.\nSoftware has always been complicated. But in recent years, this issue gets more attention as almost every detail of our lives depends on the reliability of our software. From medical devices, to gaming systems. Our alarm clocks to get us out of bed. The algorithms that set us up for a Friday night date. When everything works, everything is fine. But when they don\u0026rsquo;t work, life grinds to a halt, and we feel the desire to smash the proverbial keyboard against our heads. We ask these unanswerable questions like, why did my computer just shut off? Why is my phone acting all strange? A perfectly valid question if your job is in quality assurance. But when my Grandma calls and asks me whats going on, that\u0026rsquo;s really not OK! From our human view, it\u0026rsquo;s as if these machines have a mind of their own. Clearly they don\u0026rsquo;t. But what they do have is a complex web of relationships that\u0026rsquo;s entirely hidden from view. My Grandma has no idea, nor should she. For all effective purposes, this hidden world has a life of its own separate from our reality, and for most of us it\u0026rsquo;s indistinguishable from magic. Not the good kind of magic that makes your dreams come true. It\u0026rsquo;s the chaotic magic, of not knowing what will happen next, leaving us with a sense of frustration and anxiety. And it\u0026rsquo;s getting worse. For my Grandmas sake, I want to change this.\nIt\u0026rsquo;s not just our loyal customers who have this experience. Software developers experience this daily in their own work. As systems get more and more complex, the number of surprises increases. And getting visibility into the problem can be hard. The idea that we can patch buggy software in production has become commonplace in our society. We have trained everyone to restart their computer, close their browser and open it up again. It\u0026rsquo;s this inconvenience that is the unfortunately price we pay for convenience.\nThere are some specific feedback loops in the world of Technical Debt that I would like to draw attention to. If we consider the material in \u0026ldquo;Managing Technical Debt\u0026rdquo; from the perspective of a complex system, we will have a better chance of arriving at a realistic estimate on the true costs of technical debt. Without that accurate estimate, we risk making serious errors in our decision making. From my own analysis, I\u0026rsquo;ve identified a few feedback loops on technical debt. There may be others to consider. The ones I will consider here are:\nDeveloper morale and developer churn Decision making in the context of the entire system \u0026ldquo;Debt Normalization\u0026rdquo; Business reactions to zero marginal productivity I will discuss these individually.\nDeveloper Morale and Developer Churn I am often surprised by the disconnect between Developers and Executives on the issue of Developer Churn. As a developer myself, I see a direct connection between my satisfaction on the job, and the experience I have with my tools, and my ability to do my job well. Technical Debt is directly related. Management seems to have another perspective. Morale is something delegated to Human Resources, Total Rewards, or the employees direct report. And Churn is something that is seen as inevitable, and there\u0026rsquo;s nothing to do about it. I was surprised by this, I read almost exactly that in a manual for managers are company I once worked for. The rate of developer churn across the industry is really bad, and everyone is doing terribly. So for the 50% of companies who are above average, they think they are doing fine, while the bottom 50% feel resigned, and engage in predictable coping mechanisms. Perhaps following some of the advice in \u0026ldquo;Managing Technical Debt\u0026rdquo;, in the hope that they can increase productivity enough to afford to hire back the developers they lost to Google last year. In my experience, the most common effect of following the advice in this book is that you double your workload, you increase developers cognitive load, and you are forced to pivot to other urgent matters when the CEO sees the writing on the wall, leaving the work unfinished, thus creating a higher maintenance load than when you started. These are the sort of systems level effects that are happening in the real world.\nWhen I first started exploring some of these ideas, I was looking at some of the research into Developer Experience as a possible solution to address the abysmal attrition rate in the industry. When I first started talking about it with management and executives, I was surprised by the response. What seemed to me like an interesting avenue to explore was met with a dismissive attitude. Like Technical Debt, the solutions for Developer Experience can be quite nebulous, and management prefers things that are a bit more concrete. This makes it a challenge to make the case. Having a concrete idea of the risks and benefits is essential to get buy-in to address the problem. \u0026ldquo;Managing Technical Debt\u0026rdquo; has some great ideas in this area of how to actually find and identify the debt in concrete ways that management will understand. Unfortunately, identifying deficiencies in the technical realm is much easier than explaining them in the systems realm. The very idea that a company is a \u0026ldquo;system\u0026rdquo; is vague and hard to define. As humans, we really aren\u0026rsquo;t good at this systems level stuff.\nJust because we don\u0026rsquo;t have a good understanding yet, doesn\u0026rsquo;t mean that we aren\u0026rsquo;t making decisions in the meantime. I have often observed that in the absence of a clear understanding of the problem, companies resort to imitating industry leaders hoping that it will lead them to equal success. I suspect this is why there is a remarkable level of uniformity among large tech companies. This strategy of imitation however is terrible, for the simple reason that the industry leaders are terrible examples, not just with Technical Debt, but also in terms of employee retention and morale. We should think twice before imitating them. As an industry we need to better understand this problem and its complex relationships before we can ever hope to come up with a lasting solution.\nDecision Making in a System In my experience, it is true that well made software breeds confident and consistent decisions that improve things daily. On the flip side, poorly made software breeds hacks, stop-gaps, short-cuts, confused planning, and deadlines that never get met. Technical Debt is related to how our decisions are made. Decisions are continuously being made by everyone, from the Executive Team to Junior Developers. Decisions are not made in a vacuum. They are informed by the information at hand, and especially by the patterns that are commonly in place. We rarely hold people to a higher standard than the one we is already expressed in the existing documentation and code. Decisions happen in the context of a system, and the effects of these decisions compound daily, and multiplied by the number of developers making decisions. It\u0026rsquo;s no surprise that debt gets out of hand. If you read \u0026ldquo;Managing Technical Debt\u0026rdquo;, this issue is not discussed. This is a significant omission. Without this understanding, we underestimate our predicament, and do not fully grasp the full effect of our decision making process.\nBroken Window Theory describes the effect that broken windows in a neighborhood tend to breed more crime and vandalism. This theory has been applied to software development and can provide some insight into the problem. By fixing our broken windows, we can prevent the deleterious second order effects. It might seem like a waste of time, because the problem seems small, and our real problems seem so large. But it\u0026rsquo;s important to not underestimate how powerful these small decisions can make on larger problems throughout the system. If you are unwilling to tolerate small problems, large problems are less likely to proliferate and hide.\nDebt Normalization When you\u0026rsquo;ve been dealing with Tech Debt for so long, it\u0026rsquo;s not surprising that it becomes the new normal. This is the condition the entire industry is in. Debt has been with us for so long, and it\u0026rsquo;s so familiar, and it\u0026rsquo;s solutions are so vague and nebulous, that the issue has receded into the background as part of a new normal. The consequences of this are not good. Think about the Junior and Intermediate developers who have never known anything else. We are actually training our developers to ignore the problem and work around it with hacks and stop gaps. This is considered normal. If you have a good team lead, they will insist you put an item in the backlog. It never sees the light of day. Backlogs are places to forget things.\nAgile in a way encourages this new normal. Agile was created as part of the observation that it was hard to define the requirements for a new project up front, and that it was better to quickly iterate. This is an incredible improvement over the waterfall method. But it tends to encourage the behavior of pushing undefined requirements into the indefinite future. In the case of Technical Debt, we end up with piecemeal solutions done at a local level. You might expect Architects to dream up a solution to the problem, but they are subject to the same environment as everyone else, and often come up with insufficient solutions, but with well defined budgets and scope, that please their managers. You might also expect your Project Manager to push the agenda, but they are really only interested in features. It falls on developers to make the case, and it\u0026rsquo;s quite frustrating because it\u0026rsquo;s not something anyone wants to hear. It\u0026rsquo;s demoralizing, and a significant source of churn in my experience.\nThe cost of normalization is an invisible factor. If you ask a developer in an exit interview why they leave, they often tell you what you want to hear. They might have some complaints about this or that. But the reason they are leaving is likely unknown to even them. The sources of frustration that a developer experiences are numerous, and when they come from systemic sources, we have few tools to identify the problem, let alone solve it. We are left to cope and adapt. The common sentiment I\u0026rsquo;ve felt from developers is one of resignation. It\u0026rsquo;s the feeling of \u0026ldquo;I have believed too many empty promises. I just don\u0026rsquo;t believe anything is going to change.\u0026rdquo; It\u0026rsquo;s time to admit that we have failed at dealing with this problem and begin looking for new ways of thinking that can help us actually make a difference, and lead our organizations out of this downward spiral of resignation.\nIt\u0026rsquo;s hard to believe that companies are able to function at all, once you\u0026rsquo;ve peeked behind the curtain and seen how the sausage is made. Marginal productivity is approaching zero, and it makes people a bit desperate. Large companies are able to manage quite well by hiring top talent and trying to grow their way out of the problem. This works for a time, but actually increases the scale of the problem. As long as the economic outlook is good, we may be able to do this indefinitely. But that\u0026rsquo;s not likely to happen. When a adjustment comes, a lot of large companies will find their debt unserviceable, and have to make the hard decisions. Hiring your way out of debt is not a valid strategy, it\u0026rsquo;s a coping mechanism that will eventually fail. We can do better than this.\nBusiness reactions to zero marginal productivity The final point I want to make is about how the business responds to the condition of approaching zero marginal productivity. It\u0026rsquo;s important to emphasize the \u0026ldquo;marginal\u0026rdquo; part. Because if you ask people in the business, overall productivity has never been higher. But if you look at the increase in productivity per extra dollar spent, or per new hire, large business are seeing diminishing returns. This corresponds with my observations. But it\u0026rsquo;s also the premise of the book \u0026ldquo;The Mythical Man-Month\u0026rdquo;, which is that adding programmers to an already delayed project, delays the project even further. Not at all intuitive, but this makes sense in the context of the system of effects.\nWhat\u0026rsquo;s troubling about what I see is that not understanding the root cause leads companies to make decisions that only make matters worse, or simply delay the inevitable. Layoffs and restructuring are common responses to help boost dwindling productivity numbers, but they exacerbate the problem in the long term.\nThe other common strategy is to obsess on short term goals and KPIs. There\u0026rsquo;s nothing inherently wrong with focusing on these. The problem arises when we focus on them at the expense of a long term vision and a deeper understanding of the systemic effects. Agile encourages this behavior in it\u0026rsquo;s sprint based focus, that pushes unknowns into an indefinite future. Short term goals hides the fact that we don\u0026rsquo;t have a strategy to deal with our predicament. So we try not to think about it too much.\nIn summary Informed by this new perspective I would like to draw some conclusions:\nWe are underestimating the rate at which Technical Debt compounds because we do not understand (or discount) the human level feedback loops. We obsess over the easy solutions that technology offers, while ignoring the human factors. This creates a bias in decision making which is detrimental to the health of the organization as we favor easy solutions, over the hard to quantify human ones. Technical Debt accumulates daily by small decisions being made by everyone in the org. It\u0026rsquo;s not just the architects who are responsible for the solutions, everyone is doing it. By not proactively addressing Technical Debt on a systems level, we expose the company to significant risk. Technical Debt poses an existential threat to software companies. I don\u0026rsquo;t think this is an overstatement. It sounds crazy because we look at companies that seem to have it under control, but it\u0026rsquo;s not always the case. Smaller companies are forced to deal with this, and the solutions are pretty. If they can make the transition they survive. Otherwise they are out of business. With larger companies, this will happen on a larger time scale.\nAddressing the significant problems in the industry, such as developer churn, rising maintenance costs, rising expectations due to our deep reliance on software as a part of our daily lives, will be a defining feature of a successful company in the long term. It is costly, and it\u0026rsquo;s risky. All the more reason for leadership to step up and address the problem we have been ignoring for too long.\nReferences Baker, Christopher \u0026amp; Gordon, Ascelin \u0026amp; Bode, Michael. (2016). Ensemble ecosystem modeling for predicting ecosystem response to predator reintroduction. Conservation biology : the journal of the Society for Conservation Biology. 31. 10.1111/cobi.12798.\nBrooks, Frederick P., Jr. (1982). The Mythical man-month : essays on software engineering. Reading, Mass. :Addison-Wesley Pub. Co.\nKrutchten, Philippe \u0026amp; Nord, Robert \u0026amp; Ozkaya, Ipek. (2019). Managing Technical Debt: Reducing Friction in Software Development (1st. ed.). Addison-Wesley Professional.\n","date":"2023-02-05","permalink":"https://rrx.github.io/posts/2023-02-05-tech-debt/","tags":null,"title":"Technical Debt, A Systems Level Problem"}]